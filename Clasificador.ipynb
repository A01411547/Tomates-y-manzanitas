{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear 1 objeto ImageDataGenerator para realizar data augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1./255,  # Escala los valores de los píxeles al rango [0, 1]\n",
    "    shear_range=0.2,  # Aplica cortes aleatorios a las imágenes para facilitar el reconocimiento en diferentes condiciones\n",
    "    zoom_range=0.2,  # Aplica zoom aleatorio a las imágenes para facilitar el reconocimiento con diferentes niveles de zoom\n",
    "    horizontal_flip=True  # Voltea de manera horizontal y  aleatoriamente las imágenes \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255,  # Escala los valores de los píxeles al rango [0, 1]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de entrenamiento\n",
    "train_data = data_generator.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(150, 150),  # Cambia el tamaño de las imágenes a 150x150 píxeles\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Clasificación binaria (tomatito o manzananita)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Carga el conjunto de datos de prueba\n",
    "test_data = test_generator.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial de TensorFlow\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar capas convolucionales para extraer características\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# Agregar capas densas para la clasificación\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:00:25.948001: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 495ms/step - loss: 2.3099 - accuracy: 0.4592\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 0.6902 - accuracy: 0.5782\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.6909 - accuracy: 0.4660\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.6659 - accuracy: 0.6190\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.6578 - accuracy: 0.6531\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.6453 - accuracy: 0.6599\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 5s 453ms/step - loss: 0.6232 - accuracy: 0.6837\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 5s 451ms/step - loss: 0.6829 - accuracy: 0.6088\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.6071 - accuracy: 0.7007\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.5762 - accuracy: 0.7449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x285a90f40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(train_data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:01:12.210183: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 102ms/step - loss: 0.5525 - accuracy: 0.6907\n",
      "Test Loss: 0.5524960160255432\n",
      "Test Accuracy: 0.6907216310501099\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:02:53.468995: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 508ms/step - loss: 0.7647 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.6836 - accuracy: 0.5850\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.6522 - accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 6s 543ms/step - loss: 0.6056 - accuracy: 0.7007\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 5s 511ms/step - loss: 0.5767 - accuracy: 0.7007\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 5s 508ms/step - loss: 0.5783 - accuracy: 0.6769\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 0.5817 - accuracy: 0.6803\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 0.5768 - accuracy: 0.7313\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.5243 - accuracy: 0.7517\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.4758 - accuracy: 0.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:03:49.697625: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 123ms/step - loss: 0.5331 - accuracy: 0.7423\n",
      "Test Loss: 0.5330532193183899\n",
      "Test Accuracy: 0.7422680258750916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:03:50.465438: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 111ms/step\n",
      "Matriz de confusión:\n",
      "tf.Tensor(\n",
      "[[19 35]\n",
      " [14 29]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo secuencial de TensorFlow\n",
    "model = Sequential()\n",
    "# Agregar capas convolucionales para extraer características\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  # Agregar una capa convolucional adicional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# Agregar capas densas para la clasificación\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))  # Agregar una capa densa adicional\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Entrenar el modelo\n",
    "model.fit(train_data, epochs=10)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = predictions > 0.5\n",
    "\n",
    "# Obtener las etiquetas verdaderas del generador de flujo de datos\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix = tf.math.confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:02:01.395556: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 633ms/step - loss: 2.4084 - accuracy: 0.5272\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 5s 515ms/step - loss: 0.6038 - accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.5439 - accuracy: 0.7313\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.5559 - accuracy: 0.7279\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 0.5011 - accuracy: 0.7653\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 5s 475ms/step - loss: 0.4857 - accuracy: 0.8061\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 5s 479ms/step - loss: 0.4585 - accuracy: 0.7925\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.3900 - accuracy: 0.8367\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 5s 460ms/step - loss: 0.4315 - accuracy: 0.7823\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.4336 - accuracy: 0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:02:51.984659: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4168 - accuracy: 0.8247\n",
      "Test Loss: 0.4167843461036682\n",
      "Test Accuracy: 0.8247422575950623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:02:52.568629: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 97ms/step\n",
      "Matriz de confusión:\n",
      "tf.Tensor(\n",
      "[[32 22]\n",
      " [31 12]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo secuencial de TensorFlow\n",
    "model = Sequential()\n",
    "# Agregar capas convolucionales para extraer características\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# Agregar capas densas para la clasificación\n",
    "model.add(Dense(units=256, activation='relu'))  # Incrementar unidades a 256\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Entrenar el modelo\n",
    "model.fit(train_data, epochs=10)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = predictions > 0.5\n",
    "\n",
    "# Obtener las etiquetas verdaderas del generador de flujo de datos\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix = tf.math.confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 5s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:10:27.337607: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 32s 3s/step - loss: 0.9545 - accuracy: 0.6497\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.5826 - accuracy: 0.7789\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.4021 - accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.3256 - accuracy: 0.8537\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.2615 - accuracy: 0.9082\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.2426 - accuracy: 0.8980\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1752 - accuracy: 0.9252\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1367 - accuracy: 0.9626\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 33s 4s/step - loss: 0.1485 - accuracy: 0.9490\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1227 - accuracy: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:15:42.962509: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 10s 2s/step - loss: 0.4109 - accuracy: 0.8660\n",
      "Test Loss: 0.410885214805603\n",
      "Test Accuracy: 0.8659793734550476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:15:53.306077: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 11s 2s/step\n",
      "Matriz de confusión:\n",
      "tf.Tensor(\n",
      "[[32 22]\n",
      " [25 18]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Cargar el modelo pre-entrenado VGG16 sin incluir las capas superiores\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Congelar todas las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Agregar capas personalizadas al final del modelo\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(train_data, epochs=10)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = predictions > 0.5\n",
    "\n",
    "# Obtener las etiquetas verdaderas del generador de flujo de datos\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix = tf.math.confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación:\n",
    "Primer modelo:\n",
    "En mi primer modelo, utilicé una arquitectura de CNN con un enfoque secuencial básico. Para tener una mejora del rendimiento, implementé técnincas de data agmentation vistas en clase utilizando un generador de datos de imagen.  Junto con el escalado de píxeles, zooms aleatorios, voleto horizontal, etc. Facilitan que el modelo se entrene con una mayor variabilidad de datos y mejore su capacidad para reconocer entre objetos sus diferentes escenarios.\n",
    "Hablando más en profundidad en cuanto a la arquitectura de CNN, utilicé 2 capas convolucionales seguidas de capas de max pooling para extraer características de las imágenes. Posterior a esto, apliqué 1 capa de aplanamiento y agregué capas densas para la clasificación final.\n",
    "Las funciones de activación fueron relu en las capas convolucionales y sigmoid en la capa de salida, debido a que estaba trabajando en 1 problema de clasificación binaria.\n",
    "Para compilar el modelo, utilicé el optimizador adam y la función de perdida binary_crossentropy vista en clase para situaciones de clasificación binaria. El modelo se entreno con el conjunto de datos durante 10 epoch.\n",
    "Modelo 2:\n",
    "En mi modelo 2, realicé una modificación en la arquitectura anteriormente mencionada, esto debido a que se queria incrementar el número de unidades en la capa densa, con el objetivo de proporcionar al modelo una mayor capacidad de aprendizaje. Tambén agregué una capa densa adicional con 256 unidades y función de activación relu antes de la capa de salida. Gracias a esto el modelo tuvo una representación de caracteristicas más complejas.\n",
    "Transfer Learning con VGG16 \n",
    "Implementé el modelo pre-entrenado VGG16 aprovechando las ventajas que maneja. este modelo fue entrenado en 1 conjunto de datos grande y diverso como ImageNet, para que le proporcionará un conocimiento previo sobre la extracción de caracteristicas relevantes en imágenes.\n",
    "Utilicé la técnica Fine-tuning, donde el modelo del VGG16 y agregué capas personalizadas al final, dejé todas las capas del modelo base para de esta manera evitar que sus pesos se actualicen durante el entrenamiento. gracias a esto me facilito mantener las caracteristicas aprendidas por el modelo y evitar modificaciones de más.\n",
    " Luego agregué capas personalizadas, como una capa de aplanamiento, capas densas y 1 capa de salida, y posterior a eso entrené con los datos específicos del bronche de datos. Esto me ayudó a que el modelo se ajustará a la tarea de clasificación binaria específica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
